"""
Training Script for Cascade R-CNN + Swin Transformer
Optimized for Apple Silicon M3 Max with MPS backend
"""

import os
import sys
import argparse
import torch
from pathlib import Path

# Add project root to path
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# Import MMDet modules FIRST to register all custom classes
try:
    import mmdet.models  # Register all models
    import mmdet.datasets  # Register all datasets
    import mmdet.visualization  # Register visualizers
except ImportError as e:
    print(f"Warning: MMDetection imports failed: {e}")
    print("Some features may not work properly.")

def check_environment():
    """Check if environment is properly set up"""
    print("\n" + "=" * 60)
    print("ğŸ” í™˜ê²½ ê²€ì‚¬")
    print("=" * 60)

    # Check PyTorch
    print(f"\nâœ“ PyTorch ë²„ì „: {torch.__version__}")

    # Check MPS availability
    if torch.backends.mps.is_available():
        print("âœ“ MPS (Apple Silicon GPU) ì‚¬ìš© ê°€ëŠ¥")
        device = "mps"
    else:
        print("âš ï¸  MPS ì‚¬ìš© ë¶ˆê°€ - CPUë¡œ í•™ìŠµ")
        device = "cpu"

    # Check MMCV/MMDet
    try:
        import mmcv
        import mmdet
        print(f"âœ“ MMCV ë²„ì „: {mmcv.__version__}")
        print(f"âœ“ MMDet ë²„ì „: {mmdet.__version__}")
    except ImportError as e:
        print(f"âŒ MMDetection ì„¤ì¹˜ í•„ìš”: {e}")
        print("\nì„¤ì¹˜ ëª…ë ¹:")
        print("   pip install openmim")
        print("   mim install mmcv==2.1.0")
        print("   mim install mmdet==3.3.0")
        return False

    # Check data
    data_train = PROJECT_ROOT / "data" / "train" / "annotations.json"
    data_val = PROJECT_ROOT / "data" / "val" / "annotations.json"

    if not data_train.exists():
        print(f"\nâŒ í•™ìŠµ ë°ì´í„° ì—†ìŒ: {data_train}")
        print("\nğŸ’¡ ë¨¼ì € ë°ì´í„° ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("   python scripts/preprocess_data.py")
        return False

    if not data_val.exists():
        print(f"\nâŒ ê²€ì¦ ë°ì´í„° ì—†ìŒ: {data_val}")
        return False

    print(f"\nâœ“ í•™ìŠµ ë°ì´í„°: {data_train}")
    print(f"âœ“ ê²€ì¦ ë°ì´í„°: {data_val}")

    # Check disk space
    import shutil
    total, used, free = shutil.disk_usage(PROJECT_ROOT)
    free_gb = free / (1024**3)
    print(f"\nğŸ’¾ ì‚¬ìš© ê°€ëŠ¥í•œ ë””ìŠ¤í¬ ê³µê°„: {free_gb:.1f} GB")

    if free_gb < 10:
        print("âš ï¸  ë””ìŠ¤í¬ ê³µê°„ ë¶€ì¡± (10GB ì´ìƒ ê¶Œì¥)")

    # Memory info
    import psutil
    mem = psutil.virtual_memory()
    print(f"ğŸ’» ì‚¬ìš© ê°€ëŠ¥í•œ RAM: {mem.available / (1024**3):.1f} GB / {mem.total / (1024**3):.1f} GB")

    print("\n" + "=" * 60)
    return True, device

def train(config_file: str, work_dir: str = None, resume: bool = False, skip_confirm: bool = False):
    """
    Train Cascade R-CNN model

    Args:
        config_file: Path to config file
        work_dir: Working directory for checkpoints and logs
        resume: Resume from last checkpoint
        skip_confirm: Skip confirmation prompt for background training
    """
    from mmengine.config import Config
    from mmengine.runner import Runner

    print("\n" + "=" * 60)
    print("ğŸš€ í•™ìŠµ ì‹œì‘")
    print("=" * 60)

    # Load config
    cfg = Config.fromfile(config_file)

    # Override work_dir if specified
    if work_dir:
        cfg.work_dir = work_dir

    # Create work directory
    os.makedirs(cfg.work_dir, exist_ok=True)

    print(f"\nğŸ“ ì‘ì—… ë””ë ‰í† ë¦¬: {cfg.work_dir}")
    print(f"ğŸ“ ì„¤ì • íŒŒì¼: {config_file}")

    # Print training info
    print(f"\nâš™ï¸  í•™ìŠµ ì„¤ì •:")
    print(f"   Epochs: {cfg.train_cfg.max_epochs}")
    print(f"   Batch Size: {cfg.train_dataloader.batch_size}")
    print(f"   Learning Rate: {cfg.optim_wrapper.optimizer.lr}")
    print(f"   Device: {cfg.device}")

    # Estimate training time
    # Assuming ~2-3 hours per epoch on M3 Max
    epochs = cfg.train_cfg.max_epochs
    hours_per_epoch = 2.5
    estimated_hours = epochs * hours_per_epoch
    estimated_days = estimated_hours / 24

    print(f"\nâ±ï¸  ì˜ˆìƒ í•™ìŠµ ì‹œê°„:")
    print(f"   ì‹œê°„ë‹¹ Epoch: ~{1/hours_per_epoch:.2f}")
    print(f"   ì´ ì˜ˆìƒ ì‹œê°„: {estimated_hours:.1f}ì‹œê°„ ({estimated_days:.1f}ì¼)")

    print("\n" + "=" * 60)
    print("ğŸ’¡ í•™ìŠµ ì§„í–‰ ëª¨ë‹ˆí„°ë§:")
    print("=" * 60)
    print(f"\n1. TensorBoard:")
    print(f"   tensorboard --logdir {cfg.work_dir}")
    print(f"\n2. ë¡œê·¸ íŒŒì¼:")
    print(f"   tail -f {cfg.work_dir}/*.log")
    print(f"\n3. ì²´í¬í¬ì¸íŠ¸:")
    print(f"   ls -lh {cfg.work_dir}/*.pth")

    # Confirm before training
    if not resume and not skip_confirm:
        print("\n" + "=" * 60)
        response = input("í•™ìŠµì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
        if response.lower() != 'y':
            print("í•™ìŠµ ì·¨ì†Œë¨")
            return

    print("\n" + "=" * 60)
    print("ğŸ”¥ í•™ìŠµ ì‹œì‘...")
    print("=" * 60)

    # Build runner
    runner = Runner.from_cfg(cfg)

    # Resume or train from scratch
    if resume:
        print("\nì´ì „ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ...")
        runner.resume = True

    # Start training
    try:
        runner.train()

        print("\n" + "=" * 60)
        print("âœ… í•™ìŠµ ì™„ë£Œ!")
        print("=" * 60)

        # Find best checkpoint
        best_ckpt = Path(cfg.work_dir) / "best_coco_bbox_mAP_epoch_*.pth"
        best_ckpts = list(Path(cfg.work_dir).glob("best_*.pth"))

        if best_ckpts:
            best_ckpt = best_ckpts[0]
            print(f"\nğŸ† ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸: {best_ckpt}")
            print(f"   íŒŒì¼ í¬ê¸°: {best_ckpt.stat().st_size / (1024**2):.1f} MB")

        print(f"\nğŸ“ ëª¨ë“  ì²´í¬í¬ì¸íŠ¸: {cfg.work_dir}/")
        print(f"\në‹¤ìŒ ë‹¨ê³„: ëª¨ë¸ í‰ê°€")
        print(f"   python scripts/test.py --config {config_file} --checkpoint {best_ckpt}")

    except KeyboardInterrupt:
        print("\n\nâš ï¸  í•™ìŠµ ì¤‘ë‹¨ë¨ (Ctrl+C)")
        print(f"\nì¬ê°œí•˜ë ¤ë©´:")
        print(f"   python scripts/train.py --config {config_file} --resume")

    except Exception as e:
        print(f"\n\nâŒ í•™ìŠµ ì˜¤ë¥˜ ë°œìƒ:")
        print(f"   {e}")
        import traceback
        traceback.print_exc()

def main():
    """Main function"""
    parser = argparse.ArgumentParser(description='Train Cascade R-CNN for Korean Vehicle Detection')

    parser.add_argument(
        '--config',
        default='configs/cascade_rcnn_swin_korean.py',
        help='Config file path'
    )
    parser.add_argument(
        '--work-dir',
        help='Working directory for checkpoints and logs'
    )
    parser.add_argument(
        '--resume',
        action='store_true',
        help='Resume from last checkpoint'
    )
    parser.add_argument(
        '--skip-check',
        action='store_true',
        help='Skip environment check'
    )
    parser.add_argument(
        '--skip-confirm',
        action='store_true',
        help='Skip confirmation prompt (for background training)'
    )

    args = parser.parse_args()

    # Check environment
    if not args.skip_check:
        result = check_environment()
        if isinstance(result, tuple):
            success, device = result
            if not success:
                return
        else:
            return

    # Convert relative path to absolute
    config_file = Path(args.config)
    if not config_file.is_absolute():
        config_file = PROJECT_ROOT / config_file

    if not config_file.exists():
        print(f"\nâŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_file}")
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ì„¤ì • íŒŒì¼:")
        for cfg in (PROJECT_ROOT / "configs").glob("*.py"):
            print(f"   {cfg.relative_to(PROJECT_ROOT)}")
        return

    # Train
    train(
        config_file=str(config_file),
        work_dir=args.work_dir,
        resume=args.resume,
        skip_confirm=args.skip_confirm
    )

if __name__ == "__main__":
    main()
